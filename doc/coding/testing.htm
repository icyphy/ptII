<!-- $Id$-->
<html>
  <head>
    <meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
    <link href="../default.css" rel="stylesheet" type="text/css">
    <title>Testing Ptolemy II</title>
  </head>
  <body>
    <h1><a name="Testing Ptolemy II">Testing Ptolemy II</a></h1>
    This page is primarily for Ptolemy II Developers.  Some of the commands
    mentioned below are not included in the Ptolemy II distribution.

    <p>Contents:</p>
    <ul>
      <li> <a href="#test suite">Test Suite</a></li>
      <ul>
	<li> <a href="#JUnit">JUnit</a></li>
      </ul>
      <li> <a href="#testing java">Testing Java</a></li>
      <li> <a href="#testing documentation">Testing Documentation</a></li>
      <li> <a href="#testingxml">Testing XML</a></li>
      <li> <a href="#proofreading">Proofreading</a></li>
      <li> <a href="#runtimeTests">Runtime Tests</a></li>
      <li> <a href="#installer">Installer</a></li>
    </ul>

    <h2><a name="test suite">Test Suite</a></h2>

    <p>We have included regression tests for most of the Ptolemy II code.  Usually,
      wherever there is Java file, the tests are in the <code>test</code>
      directory.</p>

    <h3>Running the tests</h3>
    There are three types of tests:
    <ol>
      <li>Unit tests that are mostly written in Tcl, and use
	<a href="../install.htm#Jacl">Jacl</a>
	which is a 100% Java implementation of a subset of Tcl.
	These tests appear in the <code>test/</code> directories
	as <code>*.tcl</code> files
      </li>
      <li>System tests that are Ptolemy models.  These tests
	appear in the <code>test/auto/</code> directories as
	<code>*.xml</code> files .
      </li>
      <li>JUnit tests that can invoke the Tcl and auto tests above.
	These tests appear in the <code>test/junit</code>
	directories.
      </li>
      </ol>

    <dl>
      <dt>To run the tcl and model tests in one directory:</dt>
      <dd>
	<pre>
	  cd $PTII/ptolemy/actor/lib/test
	  make tests
	</pre>  
	</dd>
      <dt>To run the tcl and model tests using JUnit from the $PTII directory:</dt>
      <dd>
	<pre>
	  cd $PTII
	  ant test.single -Dtest.name=ptolemy.actor.lib.test.junit.JUnitTclTest -Djunit.formatter=plain
	</pre>
	To get usage for the test.single rule, try <code>ant test.single</code> and
	look at the first few lines of output.
      </dd>
      <dt>To run the tcl and model tests using JUnit from a <code>test/</code> directory</dt>
      <dd>
	<pre>
	  cd $PTII/ptolemy/actor/lib/test
	  $PTII/bin/ptjunit
	</pre>
      </dd>
      <dt>To run the tcl and model tests using JUnit from Eclipse</dt>
      <dd>Currently, this does not work because some of the tests must be run
	from the <code>test/</code>directory and ant under Eclipse runs from
	<code>$PTII</code>.</dd>
    </dl>
	      
    See below for details

    <p>Resources:</p>
    <ul>
      <li> Tcl Primer - A quick summary of Tcl  <a href="http://www.tcl.tk/scripting/primer.html#in_browser" target="_top"><code>http://www.tcl.tk/scripting/primer.html</code></a></li> 
      <li> The <a href="tcljava.htm"><code>java::</code> man page</a> </li>
    </ul>


    <p>We ship Jacl as a jar file called <code>$PTII/lib/ptjacl.jar</code>.</p>

    <p><code>make tests</code> will run the tests in the current directory
      and any subdirectories.</p>


    <h3>Writing your own tests</h3>

    <p>There are two ways to write tests:</p>
    <ol>
      <li> Use Vergil to create tests using the Test actor</li>
      <li> Write tests using Tcl</li>
    </ol>

    <h4>Using Vergil to write tests</h4>
    <p>The testing infrastructure will automatically run any MoML models
      located in <code>test/auto</code> directories.  (Nowhere do the names
      of these MoML files need to be listed in order for them to be run.)</p>
    <p>However, said infrastructure has to be re-built in each new
      directory containing tests. </p>

    <p>Note that MoML models used for testing should follow the following
      conventions:</p>
    <ul>
      <li> Models in <code>domains/<I>yourdomain</I>/kernel/test/auto</code>
	should <B>not</B> use actors in 
	<code>domains/<I>yourdomain</I>/lib</code>.
	<br>The reason is that these tests are really testing the domain
	actors, not the kernel.  During the nightly build, the
	testsuite runs in the <code>kernel</code> directories before running
	in the <code>lib</code> directories, so the actors in <code>lib</code>
	will not yet be built.</li>

      <li> Models that use more than one domain should be located
	in <code>domains/<I>yourdomain/test/auto</I></code>.  
	<br>The reason is that all the domains might not be built if the
	test is in <code>lib/test/auto</code> or <code>kernel/test/auto</code>.
	<br>Also, multi domain tests tend to be integration tests, not unit tests.</li>

      <li> There should be no MoML files (and no <code>test/auto</code> directories)
	in <code>ptolemy/kernel</code> and its subdirectories.
	The tests in <code>ptolemy/kernel</code> and subdirectories should
	not use code from <code>ptolemy/domains</code>
	<br> The reason is that <code>ptolemy/moml</code> and the domains
	is not yet built.  Again, we want unit tests of the kernel, not
	tests of moml and the domains here.</li>

      <li> All MoML test models should <b>not</b> use actors from 
	<code>ptolemy.actor.lib.<b>gui</b></code> because these gui actors 
	will not work during the nightly build when the models are run
	without a display.</li>

    </ul>


    To create the infrastructure for a new test directory, do the following:
    <ul>
      <li> Choose an existing <code>test/</code> directory
	that contains an <code>auto/</code> directory.
	<br>Use this as an example when creating the new test directory.
	<br>A good example is
	<code>$PTII/ptolemy/actor/lib/test</code>.</li>
      <li> Create your <code>test/</code> and
	<code>test/auto/</code> directories.
	<pre>
mkdir test test/auto
	</pre>
      </li>
      <li> cd to your <code>test/</code> directory.
	<pre>
cd test
	</pre>
      </li>
      <li> Copy over the <code>testDefs.tcl</code> and the <code>makefile</code>
	file from the example directory chosen in step 1 above.
	<pre>
cp $PTII/ptolemy/actor/lib/test/testDefs.tcl
cp $PTII/ptolemy/actor/lib/test/makefile .
	</pre>
      </li>
      <li> Modify these two files to fit your situation, which may differ from
	the example situation.  In particular:
	<dl>
	  <dt> <code>testDefs.tcl</code>
	    <dd> Adjust the value of <code>PTII</code>.  
	      <pre>
if {![info exist PTII]} {
    # If we are here, then we are probably running jacl and we can't
    # read environment variables
    set PTII [file join [pwd] <b>.. .. .. ..</b> ]
}
	      </pre>
	      The <code><b>.. .. .. ..</b></code> is the relative path
	      to the top of the Ptolemy II tree.

	      <dt> <code>makefile</code>
		<dd> Adjust <code>ME =</code> and <code>ROOT =</code>
		  <br> The <code>auto</code> directory is listed in the
		  <code>MISC_FILES</code> section:
		  <pre>
MISC_FILES =	alljtests.tcl \
    <b>auto</b>
		  </pre>
		  <br> The <code>test/makefile</code> should include a line that
		  invokes <code>test_auto</code> when the <code>test_jsimple</code> rule
		  is invoked:
		  <pre>
test_jsimple: $(EXTRA_SRCS) jclass $(KERNEL_TESTDEFS) alljtests.tcl <b>test_auto</b>
		  </pre>
		  <br>Note: <code>dummy.tcl</code> may appear in the <code>makefile</code>,
		  which some people find confusing.  The test makefile structure supports
		  running graphical and non-graphical Tcl tests.  If a particular directory
		  does not have graphical or non-graphical Tcl tests, then we 
		  set the value of <code>JGRAPHICAL_TESTS</code> or
		  <code>JSIMPLE_TESTS</code> to include <code>dummy.tcl</code> so
		  that when the makefile expands <code>JGRAPHICAL_TESTS</code>
		  or <code>JSIMPLE_TESTS</code> there will be a value there instead
		  of an empty value.  However, if either <code>JGRAPHICAL_TESTS</code>
		  or <code>JSIMPLE_TESTS</code> are set to <code>dummy.tcl</code>
		  and not referred to as a dependency, then you need not have
		  a <code>dummy.tcl</code> file.  
		  <br>For example, we have no graphical tests, so the makefile might
		  look like:
		  <pre>
# Graphical Java tests that use Tcl.
# If there are no tests, we use a dummy file so that the script that builds
# alljtests.tcl works.  If you add a test, be sure to add
# $(JGRAPHICAL_TESTS) to EXTRA_SRCS
JGRAPHICAL_TESTS = \
    dummy.tcl

EXTRA_SRCS =	$(TCL_SRCS) $(JSRCS) $(JSIMPLE_TESTS) #$(JGRAPHICAL_TESTS)
		  </pre>


	</dl>
      </li>
      <li><a name="JUnit">We</a> are moving towards using JUnit to run tests.  The <code>$PTII/build.xml</code> file
	includes targets that run all the tests in <code>**/junit/*.java</code>.  So we need to create a <code>test/junit/JUnitTclTest.java</code> file.
	That file is mostly empty, but it needs to have at least the package adjusted
	<ol>
	  <li>Create the junit directory and copy in a JUnitTclTest.java file:
	    <pre>
mkdir junit
cd junit
cp $PTII/ptolemy/actor/lib/test/junit/JUnitTclTest.java .
cp $PTII/ptolemy/actor/lib/test/junit/makefile .
            </pre>
	  <li>Edit <code>JUnitTclTest.java</code>
	    <dl>
	      <dt> Update the package:</dt>
	      <dd>
		<pre>
package ptolemy.actor.lib.test.junit;
		</pre>
	      </dd>
	      <dt>Update the comment that tells how to invoke the test in two places:</dt>
	      <dd>
		<pre>
* (cd $PTII/ptolemy/actor/lib/test/junit; java -classpath ${PTII}:${PTII}/lib/ptjacl.jar:${PTII}/lib/junit-4.8.2.jar:${PTII}/lib/JUnitParams-0.3.0.jar org.junit.runner.JUnitCore ptolemy.actor.lib.test.junit.JUnitTclTest)
                </pre>
	      </dd>
	    </dl>
	  </li>
	  <li>Edit <code>makefile</code> and adjust the paths:
	    <dl>
	      <dt>Adjust <code>ME</code> and <code>ROOT</code></dt>
	      <dd> <pre>
# Location of this directory, relative to the Ptolemy II directory
ME =		ptolemy/actor/lib/test/junit

# Root of the Ptolemy II directory
ROOT =		../../../../..
                </pre>
	      </dd>
	      <dt>Adjust the rule that runs the test:</dt>
	      <dd><pre>
tests:: $(EXTRA_SRCS) jclass test_java #test_jsimple
(cd ..; CLASSPATH="$(PTII)$(CLASSPATHSEPARATOR)$(CLASSPATH)" "$(JAVA)" $(JUNIT_JAVA_ARGS) org.junit.runner.JUnitCore ptolemy.actor.lib.test.junit.JUnitTclTest)
		</pre>
	      </dd>
	    </dl>
	  </li>
	</ol>
      </li>
      <li> Now go up one directory:
	<pre>
cd ..
	</pre>
	There needs to be a makefile here too.  It needs to name the
	<code>test/</code> directory you created.  If there already is a
	makefile, edit it.  If there is not a makefile, then
	copy the makefile from a similar directory elsewhere in the tree.

	<br>If the <code>test</code> directory was
	added, the add <code>test</code> to the <code>DIRS</code> and
	<code>MISC_FILES</code> lines:
	<pre>
DIRS =		kernel lib demo doc <b>test</b>
...
MISC_FILES =	kernel lib doc <b>test</b>
	</pre>
      </li>
      <li> If no makefile exists in the directory above test/, you will need
	to create one and repeat this procedure in the next directory up until
	you find an existing makefile.
      </li>
    </ul>

    <p>When you have done all this, the tests in your new test/auto directory ought to run in the nightly build.</p>

    <p>The test passes if it does not throw an exception</p>

    <p>The <a href="../codeDoc/ptolemy/actor/lib/Test.html">Test actor</a>
      (located under  "more libraries") 
      can be used to compare the first few results
      of a simulation with a known good results.  If the comparison fails,
      then the test fails.</p>  

    <p>If a test is in the optional <code>test/auto/knownFailedTests</code> 
      directory, then it will be marked as a known failure if it fails.
      (For more information, see
      <a href="#CheckingKnownFailedTests">Checking Known Failed Test Results</a>
      below).</p>

    <p>Using Vergil to write tests is quite a bit easier than writing Tcl
      code, but it is much more difficult to handle corner cases and test
      for erroneous conditions by writing models.  Tcl tests are unit tests,
      whereas tests that use models are system tests and may mask unit
      test bugs.</p>  


    <h4>Writing Tcl Tests</h4>

    <p>The test suite infrastructure is based on the Tcl test suite code.</p>

    <p>The file <a href="../../util/testsuite/testDefs.tcl"><code>$PTII/util/testsuite/testDefs.tcl</code></a> defines the Tcl proc <code>test</code>.</p>

    <p><code>test</code> takes five arguments:</p>
    <ol>
      <li> The name of the test, for example: <code>foo-1.0</code>
	<br> The name of the test should strictly follow the format below.
	The Tcl tests that come with the Tcl distribution follow a similar
	format, so unless there is a strong need to not follow the format,
	please stick with what works.
	<ul>
	  <li> The first part of
	    name of the test should reflect the command that is
	    being tested.</li>

	  <li> The test number should be separated by a dash '<code>-</code>'</li>

	  <li> Each test number consists of a major value and a minor value,
	    separated by a dot.  Usually the major value changes as different
	    parts of the command are being tested.  The minor value changes
	    for different tests for the particular part of the command under test.</li>

	  <li> Test numbers usually start with <code>1</code>, though if
	    you are
	    doing setup, you can start with <code>0</code>.</li>

	  <li> If you go back later and want to stick a test in between
	    <code>foo-1</code> and <code>foo-2</code>, you can always call
	    your new test <code>foo-1.1</code></li>
	</ul>
      </li>

      <li> The test description, usually a single sentence.</li>

      <li> The contents of the test, usually Tcl code that does the action to
	be tested.  The last line of the contents should return a value.</li>

      <li> The results to be compared against.</li>

      <li> The last argument is optional and determines what sort of test is
	being run.  The default value is <code>NORMAL</code>, which means that
	the test should pass under normal conditions.  If the value is
	<code>KNOWN_FAILED</code>, then the test is expected to fail, but
	eventually will be fixed.  By using <code>KNOWN_FAILED</code>, developers
	can mark tests that they know are failing, which will save other
	developers from attempting to debug known problems.
      </li>
    </ol>

    Below is a sample piece of code that sources the
    <code>testDefs.tcl</code> file and then runs one test.  The code below
    has the incorrect value return results to be compared against, so the
    test suite properly indicates that the test failed.

    <tcl><pre>
if {[string compare test [info procs test]] == 1} then {
    source [file join $PTII util testsuite testDefs.tcl]
} {}
test testExample-1.1 {This is the first test example, it does very little} {
    catch {this is an error} errMsg1
    set a "this is the value of a"
    list $errMsg1 $a
} {{invalid command name "this"} {this is NOT the value of a}}
    </pre></tcl>

    <h3>Parts of a test file</h3>
    Test files should be located in the <code>test</code> directory.

    <p>It is better to have many small test files as opposed to a few
      large test files so that other developers can quickly find the tests
      for the class they are working with.  Usually tests for the class
      <code>Foo</code> are found in the file <code>test/Foo.tcl</code></p>

    <p>Each test file should have the following parts:</p>
    <ol>

      <li> The Copyright</li>

      <li> The code that loads the test system package
	<pre>
if {[string compare test [info procs test]] == 1} then {
    source testDefs.tcl
}
	</pre>
	Each directory contains a <code>testDefs.tcl</code> file which
	in turn sources <a href="../../util/testsuite/testDefs.tcl"><code>$PTII/util/testsuite/testDefs.tcl</code></a>.  The idea here is that
	if the test framework changes, each test file need not be updated.
      </li>

      <li> A line that the user can uncomment if they want the test system to
	produce verbose messages:
	<pre>
#set VERBOSE 1
	</pre>
      </li>

      <li> The individual tests, which should loosely follow the Ptolemy II
	file format standard:
	<pre>
############################################################################
#### Foo
test Foo-1.1 {Test out Foo} {

} {}
	</pre>
      </li>

    </ol>

    <h3><a name="test styles">Test Styles</a></h3>
    There are two types of tests:
    <ol>
      <li> Tests that handle all necessary setup in each individual test.</li>

      <li> Tests that rely on the earlier tests to do setup.</li>
    </ol>

    In general, each test file should be able to be run over and over again
    in a binary without exiting the binary (it should be idempotent).

    <p>It is up to the author of the tests as to whether each individual
      test does all the set up necessary.  If each test is atomic, then it
      makes it easy to highlight the text of an individual test and run it.
      If lots of tests are sharing common setup, then using a separate
      procedure to do setup might help.  On the negative side, atomic tests
      usually are longer and have more complicated return results.</p>

    <hr>
    <h2><a name="testing java">Testing Java</a></h2>

    <h3><a name="jacl">Jacl</a></h3>
    Jacl is a 100% Java implementation of a subset of Tcl.
    We use Jacl to test Java by writing Tcl code that exercises the Java classes.

    <h3>Running the tests</h3>
    To run the all the tests, do <code>cd $PTII; make tests</code>

    <p>If you run <code>make</code> in a test directory that contains
      tests written in Tcl for testing Java classes, then the 'right thing'
      should just happen.</p>

    <p>If you are running in Eclipse:</p>
    <ol>
      <li> In Eclipse, go to Run -&gt; Debug Configurations</li>
      <li> Select Java Application and then click the New icon.</li>
      <li> In the Main tab, set the "Name:" to ptjacl, in "Main class:", enter <code>tcl.lang.Shell</code>.</li>
      <li> <i>Optional:</i> In the Arguments tab, under "Program arguments", enter <code>alljtests.tcl</code> or any individual test tcl file. 
	(E.g. <code>SimpleDelay.tcl</code>).
	Or, leave the "Program arguments" field blank and when ptjacl is running (see below), enter text in to the Eclipse console. 
      </li>
      <li> <i>Optional:</i> In the Arguments tab, under "VM arguments", enter <code>-Dptolemy.ptII.dir=<I>your PtII directory</I></code>
	<br>(E.g. <code>-Dptolemy.ptII.dir=c:/hyzheng/ptII</code>).<br /> In case your directory path contains
	spaces, you need to use quotes. (E.g. <code>-Dptolemy.ptII.dir="c:/my workspace/ptII"</code>).
      </li>

      <li> In the "Working directory:" pane, select "Other:", browse to the directory containing the tcl 
	tests.
	<br> (E.g. <code>C:\hyzheng\ptII\ptolemy\domains\de\lib\test</code>)
      </li>
      <li> Select Debug.</li>

    </ol>

    <p>The nice thing of using Eclipse is that you can very easily locate where 
      the exception is thrown by clicking the classes listed in the stack trace. 
      You may further register a breakpoint to do more diagnosis.</p>


    <h3>Writing Tests for Java </h3>
    <p>Below we discuss some of the details of writing tests in Tcl that test
      Java classes.<p>
      <h4>Simple Example</h4>
    <p>Jacl allows us to instantiate objects in a class and call public
      methods.  We use Jacl and the standard Tcl test bed to create tests.
      In the example below, we call <code>java::new</code> to create an
      instance of the Java <code>NamedObj</code> class.  We can then
      call public methods of <code>NamedObj</code> by referring to the
      Java object handle <code>$n</code>:
      <pre>
test NamedObj-2.1 {Create a NamedObj, set the name, change it} {
    set n [java::new pt.kernel.NamedObj]
    set result1 [$n getName]
    $n setName "A Named Obj"
    set result2 [$n getName]
    list $result1 $result2
} {{} {A Named Obj}}
      </pre>

      <h3><a name="CheckingKnownFailedTests">Checking Known Failed Test Results</a></h3>

      Note that you can combine the Tcl tests and the MoML tests
      by calling <code>createAndExecute</code>.  Even better, you
      can test for specific error messages with:
      <pre>
test SDFSchedulerErrors-1.0 {} {
    catch {createAndExecute "rateConsistency.xml"} errorMessage
    list $errorMessage
} {{ptolemy.kernel.util.IllegalActionException: Failed to compute schedule:
in .rateConsistency.SDF Director
Because:
No solution exists for the balance equations.
Graph is not consistent under the SDF domain detected on external 
port .rateConsistency.actor.port2}}
      </pre>

      <H4>Java Tcl Test Files</H4>
    <p>It is best if each Java class has a separate Tcl file that contains tests.
      The base of the name of the Tcl test file should be the same of the Java
      class being tested.  The Tcl test file should be located in the
      <code>test</code> subdirectory of the directory where the Java class
      is defined.</p>

    <p>For example, if we are testing <code>NamedObj.java</code>, then
      the Tcl test file should be at <code>test/NamedObj.tcl</code>.</p>


    <h3><a name="codecoverage">Code Coverage</a></h3>
    <p>We use ant and Cobertura for code coverage.  See <a href="ant.htm">$PTII/doc/coding/ant.htm</a> for information about ant.</p>
    <p>For code coverage, see <a href="http://chess.eecs.berkeley.edu/ptexternal#in_browser" target="_top">http://chess.eecs.berkeley.edu/ptexternal</a>.</p>
    

    <hr>
    <h2><a name="testing documentation">Testing Documentation</a></h2>

    The Ptolemy II documentation is written in HTML.  There are several tools
    that can be used.
    <h3>wget</h3>
    The <code>wget</code> program can be used to craw the html pages
    of the release when it is on a website.  

    <br>On the website, create a temporary top level <code>$PTII/index.htm</code>
    that includes a link to <code>doc/index.htm</code>


    <br>run <code>wget</code>
    <pre>
wget -np -m http://ptolemy.eecs.berkeley.edu/ptolemyII/<I>release</I>/index.htm &gt;&amp; wget.out
    </pre>
    This will generate lots of files in a <code>ptolemy.eecs.berkeley.edu</code>
    directory.  This directory can be removed:
    <pre>
rm -rf ptolemy.eecs.berkeley.edu
    </pre>

    Look for "<code>Not Found</code>"
    <pre>
awk '{ if ($0 ~ /Not Found/) { print lineTwo} else {lineTwo = lineOne; lineOne=$0}}' wget.out | uniq | awk '{print $NF}'| grep -v '%5C' | sort  
    </pre>



    <h3>weblint</h3>

    Weblint tells the user about html errors.  Weblint was once obtained from
    <a href="ftp://ftp.cre.canon.co.uk/pub/weblint/weblint.tar.gz"><code>ftp://ftp.cre.canon.co.uk/pub/weblint/weblint.tar.gz</code></a> but has since moved, try
    using google.
    <br>To run <code>weblint</code>:
    <pre>
cd $PTII
make weblint
    </pre>

    <h3>htmlchek</h3>

    Htmlchek is another tool that tells the user about html errors.
    <code>htmlchek</code> also checks for bad links.  The
    <code>htmlchek</code> output is a little hard to read, so we tend to
    use <code>weblint</code> for checking individual files.
    <code>htmlchek</code> was once available at
    <a href="ftp://ftp.cs.buffalo.edu/pub/htmlchek/"><code>ftp://ftp.cs.buffalo.edu/pub/htmlchek/</code></a> but has since moved, try using google.

    <p> The best way to run <code>htmlchek</code> is to create a sample
      distribution, create the files in the <code>codeDoc</code> directory
      and then run <code>htmlchek</code></p>

    <ol>
      <li> Create the test distribution:
	<pre>
cd /users/ptII/adm/gen-latest; make htmlchek
	</pre>
      </li>
      <li> Reset <code>PTII</code> to point to the test distribution:
	<pre>
setenv PTII /users/ptII/adm/dists/ptII-latest
cd PTII
	</pre>
      </li>
      <li> Run <code>make install</code>.  This will make the Itcl HTML docs
	twice, which will populate the <code>doc/codeDoc</code> directories.
	You need to make the Itcl HTML docs twice so that the cross references are
	correct.
      </li>
      <li> Run <code>make htmlchek</code></li>

    </ol>



    The output ends up in five files
    <ul>
      <li> <code>htmlchekout.ERR</code> - HTML usage errors</li>
      <li> <code>htmlchekout.NAME</code> - Locations in the specified files
	that ware not referenced by any of those files
      </li>
      <li> <code>htmlchekout.HREF</code> - References from the specified files
	that are not found in the files.  This file is by far the most important
	file to look at.
      </li>
      <li> <code>htmlchekout.SRC</code> - References to online images.</li>
      <li> <code>htmlchekout.MAP</code> - Cross dependency information.</li>
    </ul>

    <p> All of the references in <code>htmlchekout.HREF</code> that point
      to <code>.html</code> files should be checked.  References to non-HTML
      files appear in <code>htmlchekout.HREF</code> because the non-HTML
      files were not included in the list of files that
      <code>htmlchek</code> ran on.  One quick way to search all the the <code>*.html</code> files is</p>
    <pre>
cd $PTII
grep mystring `find . -name "*.html" -print`
    </pre>

    <h3>Spell checking</h3>
    <a href="../../util/testsuite/ptspell"><code>$PTII/util/testsuite/ptspell</code></a>
    is a Ptolemy II specific spelling checker.

    <code>ptspell</code> has the following features:
    <ul>
      <li> It uses
	<a href="../../util/testsuite/ptlocaldict"><code>$PTII/util/testsuite/ptlocaldict</code></a>
	as a local dictionary of acceptable words that are not in the
	regular system dictionary. <code>ptlocaldict</code>
	is kept in ASCII sort order.
      </li>

      <li> <code>ptspell</code> splits words up that contain embedded
	capital letters and then runs spell again.  Thus, <code>ptspell</code>
	can report spelling problems in variable, method and class names.
	This mechanism also reduces the number of words that are reported as
	misspelled because the word consists of two words stuck together.
      </li>

      <li> If <code>/usr/local/bin/ispell</code> is present, then
	it will use it.  If you are running under Windows with Cygwin, you can
	download a prebuilt version of <code>ispell</code> from
	<a href="http://ptolemy.eecs.berkeley.edu/tycho/tychoTools.htm#in_browser" target="_top"><code>http://ptolemy.eecs.berkeley.edu/tycho/tychoTools.htm</code></a>
      </li>

    </ul>

    <p>
      Checking the spelling in all the HTML files can be done with:</p>
    <pre>
cd $PTII
ptspell `find . -name "*.html" -print`
    </pre>

    <p>Spell check the comments in the demos</p>
    <pre>
cd $PTII
adm/bin/ptIItxtfiles &gt; /tmp/f
grep demo /tmp/f | grep .xml &gt; /tmp/m
ptspell `cat /tmp/m
    </pre>

    <h3>Check the distribution for bogus files</h3>
    Run the following makefile rules and commands:
    <dl>
      <dt> <code>make realclean</code>

	<dd> This will remove the <code>tclIndex</code> files and the files in
	  <code>doc/codeDoc</code>.  The reason to remove the
	  <code>codeDoc</code> files is so that we don't ship HTML files for any
	  classes that have been removed.

	  <dt> <code>make install</code>
	    <dd> This will recreate the <code>tclIndex</code> files and the
	      <code>doc/codeDoc</code> files.

	      <dt> <code>make checkjunk</code>
		<dd> Look for files in the distribution that should not be there.

		  <dt> <code>adm/bin/chkgifs</code>
		    <dd> This file looks for gif files that are not used by HTML files
		      in the distribution.

    </dl>

    <h2><a name="testingxml">Testing XML</a></h2>
    The parser we use in
    <code>$PTII/com/microstar</code>
    is a non validating parser.
    If you are writing MoML code, you might want to run your
    file through a validating parser, below are a few references:
    <ul>
      <li> <a href="http://www.hcrc.ed.ac.uk/~richard/xml-check.html#in_browser" target="_top">wwww.hcrc.edu.ac.uk</a></li>

      <li> <a href="http://dir.yahoo.com/Computers_and_Internet/Data_Formats/HTML/Validation_and_Checkers/#in_browser" target="_top">Yahoo HTML Validators</a></li>
    </ul>

    <h2><a name="proofreading">Proofreading</a></h2>

    Below are some guidelines on proofreading documentation
    <ol>
      <li> Proofreaders should write their names on the front page
	of the document.</li>

      <li> In general, write big, and use a red pen.</li>

      <li> Each page that has a typo should have a mark at the top of the page
	so that editors can easily find the typo.</li>

      <li> Proofreading symbols can be found at<a href="http://webster.commnet.edu/writing/symbols.htm#in_browser" target="_top"><code>http://webster.commnet.edu/writing/symbols.htm</code></a></li>
    </ol>

    <h2><a href="#runtimeTests">Runtime Tests</a></h2>
    <ol>

      <li> It is easier to work with the 
	<a href="../webStartHelp.htm">Webstart</a> version and check for missing
	files than it is to work with the installer.
	<br>Install <a href="../install.htm#X10">X10</a> and rerun
	<code>cd $PTII;./configure</code>

	<br>Build a webstart version with
	<pre>
cd $PTII
make install jnlp_all
	</pre>
	Invoke Webstart by pointing your browser at
	<a href="../../vergil.jnlp"><code>$PTII/vergil.jnlp</code></a>
      </li>
      <li>Use the <code>about::copyright</code> facility to test
	for missing files and models that are the wrong size.
      </li>
    </ol>

    <h2><a name="installer">How to test the installer</a></h2>
    For each case
    <ol>
      <li> Install with the included JVM but don't include the sources</li>
      <li> Install without the included JVM but don't include the sources</li>
      <li> Install with the included JVM but include the sources</li>
      <li> WebStart</li>
    </ol>

    Do the following:
    <ol>
      <li> Start up all the menu choices, verify that the initial screen
	has the right version number
      </li>
      <li> Start up vergil, check the copyrights by expanding the configuration
	and run all the demos.
      </li>
    </ol>

    Other things to try
    <ol>
      <li> Build the sources that are included in the installer
	<pre>
cd c:/Ptolemy/ptII5.1
export PTII=c:/Ptolemy/ptII5.1
./configure
 make fast install tests &gt;&amp; make.out &amp;
	</pre>
      </li>
      <li> Run diff against old versions</li>
    </ol>

    <p><font size="2" color="#cc0000">Last Updated: $Date$</font></p>
  </body>
</html>
